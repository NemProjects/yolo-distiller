#!/usr/bin/env python3
"""
VOC Dataset YOLOv11m ‚Üí YOLOv11s Knowledge Distillation Experiment
ÏµúÏ†ÅÌôîÎêú ÏÑ§Ï†ïÏúºÎ°ú Î≤†Ïù¥Ïä§ÎùºÏù∏Í≥º KD ÏÑ±Îä• ÎπÑÍµê
"""

import os
import time
import json
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import pytz
from ultralytics import YOLO

def get_kst_timestamp():
    """ÌïúÍµ≠ ÏãúÍ∞Ñ ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ ÏÉùÏÑ±"""
    kst = pytz.timezone('Asia/Seoul')
    now = datetime.now(kst)
    return now.strftime("%Y%m%d_%H%M%S"), now.strftime("%Y-%m-%d %H:%M:%S KST")

def format_training_time(seconds):
    """ÌïôÏäµ ÏãúÍ∞ÑÏùÑ Ïãú:Î∂Ñ:Ï¥à ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = int(seconds % 60)
    return f"{hours}h {minutes}m {seconds}s"

def get_model_size(model_path):
    """Î™®Îç∏ ÌååÏùº ÌÅ¨Í∏∞Î•º MB Îã®ÏúÑÎ°ú Î∞òÌôò"""
    if os.path.exists(model_path):
        size_bytes = os.path.getsize(model_path)
        return size_bytes / (1024 * 1024)  # MBÎ°ú Î≥ÄÌôò
    return 0

def run_baseline_yolo11s(epochs=70, batch=64, workers=12):  # Changed to 70 epochs for thorough KD validation
    """YOLOv11s Î≤†Ïù¥Ïä§ÎùºÏù∏ ÌïôÏäµ"""
    print("=" * 60)
    print("üöÄ YOLOv11s Î≤†Ïù¥Ïä§ÎùºÏù∏ ÌïôÏäµ ÏãúÏûë")
    print(f"üìä ÏÑ§Ï†ï: epochs={epochs}, batch={batch}, workers={workers}")
    print("=" * 60)

    start_time = time.time()

    # ÌïôÏÉù Î™®Îç∏ Ï¥àÍ∏∞Ìôî
    student_model = YOLO("yolo11s.pt")

    # ÌïôÏäµ Ïã§Ìñâ
    results = student_model.train(
        data="VOC.yaml",
        epochs=epochs,
        batch=batch,
        workers=workers,
        exist_ok=True,
        name=f"voc_baseline_yolo11s_optimized_{get_kst_timestamp()[0]}"
    )

    end_time = time.time()
    training_time = end_time - start_time

    print(f"‚úÖ Î≤†Ïù¥Ïä§ÎùºÏù∏ ÌïôÏäµ ÏôÑÎ£å! ÏÜåÏöîÏãúÍ∞Ñ: {format_training_time(training_time)}")

    return {
        "training_time": training_time,
        "training_time_str": format_training_time(training_time),
        "model_path": results.save_dir / "weights" / "best.pt",
        "results": results
    }

def run_kd_yolo11m_to_11s(epochs=70, batch=64, workers=12):  # Changed to 70 epochs for thorough KD validation
    """YOLOv11m ‚Üí YOLOv11s Knowledge Distillation ÌïôÏäµ"""
    print("=" * 60)
    print("üéì YOLOv11m ‚Üí YOLOv11s KD ÌïôÏäµ ÏãúÏûë")
    print(f"üìä ÏÑ§Ï†ï: epochs={epochs}, batch={batch}, workers={workers}")
    print("=" * 60)

    start_time = time.time()

    # ÍµêÏÇ¨ Î™®Îç∏Í≥º ÌïôÏÉù Î™®Îç∏ Ï¥àÍ∏∞Ìôî
    teacher_model = YOLO("yolo11m.pt")
    student_model = YOLO("yolo11s.pt")

    print(f"üë®‚Äçüè´ Teacher: YOLOv11m ({teacher_model.model.model[-1].nc} classes)")
    print(f"üë®‚Äçüéì Student: YOLOv11s ({student_model.model.model[-1].nc} classes)")

    # KD ÌïôÏäµ Ïã§Ìñâ
    results = student_model.train(
        data="VOC.yaml",
        teacher=teacher_model.model,
        distillation_loss="cwd",
        epochs=epochs,
        batch=batch,
        workers=workers,
        exist_ok=True,
        name=f"voc_kd_yolo11s_from_11m_optimized_{get_kst_timestamp()[0]}"
    )

    end_time = time.time()
    training_time = end_time - start_time

    print(f"‚úÖ KD ÌïôÏäµ ÏôÑÎ£å! ÏÜåÏöîÏãúÍ∞Ñ: {format_training_time(training_time)}")

    return {
        "training_time": training_time,
        "training_time_str": format_training_time(training_time),
        "model_path": results.save_dir / "weights" / "best.pt",
        "results": results
    }

def extract_metrics_from_results(results_dir):
    """results.csvÏóêÏÑú ÏµúÏ¢Ö Î©îÌä∏Î¶≠ Ï∂îÏ∂ú"""
    csv_path = os.path.join(results_dir, "results.csv")
    if not os.path.exists(csv_path):
        return {}

    df = pd.read_csv(csv_path)
    last_row = df.iloc[-1]

    return {
        "metrics/precision(B)": last_row.get("metrics/precision(B)", 0),
        "metrics/recall(B)": last_row.get("metrics/recall(B)", 0),
        "metrics/mAP50(B)": last_row.get("metrics/mAP50(B)", 0),
        "metrics/mAP50-95(B)": last_row.get("metrics/mAP50-95(B)", 0),
        "fitness": last_row.get("fitness", 0) if "fitness" in last_row else 0
    }

def create_comparison_chart(baseline_metrics, kd_metrics, save_path):
    """ÎπÑÍµê Ï∞®Ìä∏ ÏÉùÏÑ±"""
    metrics = ['precision', 'recall', 'mAP50', 'mAP50-95']
    baseline_values = [
        baseline_metrics.get("metrics/precision(B)", 0),
        baseline_metrics.get("metrics/recall(B)", 0),
        baseline_metrics.get("metrics/mAP50(B)", 0),
        baseline_metrics.get("metrics/mAP50-95(B)", 0)
    ]
    kd_values = [
        kd_metrics.get("metrics/precision(B)", 0),
        kd_metrics.get("metrics/recall(B)", 0),
        kd_metrics.get("metrics/mAP50(B)", 0),
        kd_metrics.get("metrics/mAP50-95(B)", 0)
    ]

    # Í∞úÏÑ†Ïú® Í≥ÑÏÇ∞
    improvements = []
    for b, k in zip(baseline_values, kd_values):
        if b > 0:
            improvement = ((k - b) / b) * 100
            improvements.append(improvement)
        else:
            improvements.append(0)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Ï†àÎåÄÍ∞í ÎπÑÍµê
    x = range(len(metrics))
    width = 0.35
    ax1.bar([i - width/2 for i in x], baseline_values, width, label='Baseline', alpha=0.8, color='skyblue')
    ax1.bar([i + width/2 for i in x], kd_values, width, label='Knowledge Distillation', alpha=0.8, color='lightgreen')

    ax1.set_xlabel('Metrics')
    ax1.set_ylabel('Value')
    ax1.set_title('Baseline vs Knowledge Distillation Performance\n(VOC Dataset - YOLOv11m‚ÜíYOLOv11s)')
    ax1.set_xticks(x)
    ax1.set_xticklabels(metrics)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Í∞í ÌëúÏãú
    for i, (b, k) in enumerate(zip(baseline_values, kd_values)):
        ax1.text(i - width/2, b + 0.01, f'{b:.3f}', ha='center', va='bottom')
        ax1.text(i + width/2, k + 0.01, f'{k:.3f}', ha='center', va='bottom')

    # Í∞úÏÑ†Ïú® ÎπÑÍµê
    colors = ['red' if imp < 0 else 'green' for imp in improvements]
    bars = ax2.bar(metrics, improvements, color=colors, alpha=0.7)
    ax2.set_xlabel('Metrics')
    ax2.set_ylabel('Improvement (%)')
    ax2.set_title('Performance Change with Knowledge Distillation\n(VOC Dataset - YOLOv11m‚ÜíYOLOv11s)')
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax2.grid(True, alpha=0.3)

    # Í∞úÏÑ†Ïú® Í∞í ÌëúÏãú
    for bar, imp in zip(bars, improvements):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + (0.5 if height >= 0 else -0.5),
                f'{imp:.2f}%', ha='center', va='bottom' if height >= 0 else 'top')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

def run_full_experiment(test_epochs=70):
    """Ï†ÑÏ≤¥ Ïã§Ìóò Ïã§Ìñâ (Í∏∞Î≥∏ 70 ÏóêÌè¨ÌÅ¨Î°ú Ï∂©Î∂ÑÌïú Í≤ÄÏ¶ù)"""
    timestamp, kst_time = get_kst_timestamp()

    print("üî¨ VOC YOLOv11m ‚Üí YOLOv11s Knowledge Distillation Ïã§Ìóò ÏãúÏûë")
    print(f"‚è∞ ÏãúÏûë ÏãúÍ∞Ñ: {kst_time}")
    print("üí™ ÏµúÏ†ÅÌôîÎêú ÏÑ§Ï†ï: batch=64, workers=12 (A100 40GB ÏµúÏ†ÅÌôî)")

    # 1. Î≤†Ïù¥Ïä§ÎùºÏù∏ ÌïôÏäµ
    baseline_result = run_baseline_yolo11s(epochs=test_epochs)
    baseline_metrics = extract_metrics_from_results(baseline_result["model_path"].parent.parent)

    # 2. KD ÌïôÏäµ
    kd_result = run_kd_yolo11m_to_11s(epochs=test_epochs)
    kd_metrics = extract_metrics_from_results(kd_result["model_path"].parent.parent)

    # 3. Í≤∞Í≥º Ï†ïÎ¶¨
    experiment_results = {
        "experiment_info": {
            "timestamp": timestamp,
            "timestamp_kst": kst_time,
            "data": "VOC.yaml",
            "dataset_size": "VOC 2012 (17,125 train, 4,952 val)",
            "epochs": 70,  # Thorough validation epochs
            "batch_size": 64,
            "workers": 12,
            "teacher_model": "yolo11m",
            "student_model": "yolo11s",
            "distillation_loss": "cwd",
            "device": "0"
        },
        "baseline": {
            "training_time": baseline_result["training_time"],
            "training_time_str": baseline_result["training_time_str"],
            "model_path": str(baseline_result["model_path"]),
            "metrics": baseline_metrics
        },
        "knowledge_distillation": {
            "training_time": kd_result["training_time"],
            "training_time_str": kd_result["training_time_str"],
            "model_path": str(kd_result["model_path"]),
            "metrics": kd_metrics
        }
    }

    # ÎπÑÍµê Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
    comparison = {}
    for metric in ["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)", "metrics/mAP50-95(B)"]:
        baseline_val = baseline_metrics.get(metric, 0)
        kd_val = kd_metrics.get(metric, 0)
        improvement = ((kd_val - baseline_val) / baseline_val * 100) if baseline_val > 0 else 0

        comparison[metric] = {
            "baseline": baseline_val,
            "kd": kd_val,
            "improvement_percent": improvement
        }

    # ÌïôÏäµ ÏãúÍ∞Ñ ÎπÑÍµê
    comparison["training_time"] = {
        "baseline": baseline_result["training_time"],
        "kd": kd_result["training_time"],
        "baseline_str": baseline_result["training_time_str"],
        "kd_str": kd_result["training_time_str"]
    }

    # Î™®Îç∏ ÌÅ¨Í∏∞ ÎπÑÍµê
    comparison["model_size_mb"] = {
        "baseline": get_model_size(baseline_result["model_path"]),
        "kd": get_model_size(kd_result["model_path"])
    }

    experiment_results["comparison"] = comparison

    # 4. Í≤∞Í≥º Ï†ÄÏû•
    output_dir = f"kd_experiments_voc_11m_to_11s"
    os.makedirs(output_dir, exist_ok=True)

    # JSON Ï†ÄÏû•
    json_path = f"{output_dir}/kd_results_voc_11m_to_11s_{timestamp}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(experiment_results, f, indent=4, ensure_ascii=False)

    # CSV ÏöîÏïΩ Ï†ÄÏû•
    summary_data = {
        'Metric': ['precision', 'recall', 'mAP50', 'mAP50-95'],
        'Baseline': [
            baseline_metrics.get("metrics/precision(B)", 0),
            baseline_metrics.get("metrics/recall(B)", 0),
            baseline_metrics.get("metrics/mAP50(B)", 0),
            baseline_metrics.get("metrics/mAP50-95(B)", 0)
        ],
        'KD': [
            kd_metrics.get("metrics/precision(B)", 0),
            kd_metrics.get("metrics/recall(B)", 0),
            kd_metrics.get("metrics/mAP50(B)", 0),
            kd_metrics.get("metrics/mAP50-95(B)", 0)
        ]
    }

    for i, metric in enumerate(['precision', 'recall', 'mAP50', 'mAP50-95']):
        baseline_val = summary_data['Baseline'][i]
        kd_val = summary_data['KD'][i]
        improvement = ((kd_val - baseline_val) / baseline_val * 100) if baseline_val > 0 else 0
        if i == 0:
            summary_data['Improvement (%)'] = [improvement]
        else:
            summary_data['Improvement (%)'].append(improvement)

    df_summary = pd.DataFrame(summary_data)
    csv_path = f"{output_dir}/kd_summary_voc_11m_to_11s_{timestamp}.csv"
    df_summary.to_csv(csv_path, index=False, float_format='%.4f')

    # Ï∞®Ìä∏ ÏÉùÏÑ±
    chart_path = f"{output_dir}/kd_comparison_voc_11m_to_11s_{timestamp}.png"
    create_comparison_chart(baseline_metrics, kd_metrics, chart_path)

    print("=" * 60)
    print("üéâ Ïã§Ìóò ÏôÑÎ£å!")
    print(f"üìÅ Í≤∞Í≥º Ï†ÄÏû• ÏúÑÏπò: {output_dir}/")
    print(f"üìä JSON: {json_path}")
    print(f"üìà CSV: {csv_path}")
    print(f"üìä Ï∞®Ìä∏: {chart_path}")
    print("=" * 60)

    return experiment_results

def extract_epoch_metrics(csv_path, target_epoch):
    """Í∏∞Ï°¥ Í≤∞Í≥ºÏóêÏÑú ÌäπÏ†ï ÏóêÌè¨ÌÅ¨Ïùò Î©îÌä∏Î¶≠ Ï∂îÏ∂ú"""
    import pandas as pd

    if not os.path.exists(csv_path):
        return {}

    df = pd.read_csv(csv_path)
    target_row = df[df['epoch'] == target_epoch]

    if target_row.empty:
        return {}

    row = target_row.iloc[0]
    return {
        "metrics/precision(B)": row.get("metrics/precision(B)", 0),
        "metrics/recall(B)": row.get("metrics/recall(B)", 0),
        "metrics/mAP50(B)": row.get("metrics/mAP50(B)", 0),
        "metrics/mAP50-95(B)": row.get("metrics/mAP50-95(B)", 0),
        "training_time": row.get("time", 0),
        "epoch": target_epoch
    }

def test_extended_kd_150():
    """ÌôïÏû•Îêú KD ÌÖåÏä§Ìä∏ - 150 ÏóêÌè¨ÌÅ¨ (Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 vs KD 150)"""
    print("üöÄ ÌôïÏû•Îêú KD ÌÖåÏä§Ìä∏ ÏãúÏûë (150 ÏóêÌè¨ÌÅ¨)")
    print("üìä Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 ÏóêÌè¨ÌÅ¨ vs KD 150 ÏóêÌè¨ÌÅ¨ ÎπÑÍµê")
    print("üìä ÏµúÏã† Adaptive Í∞úÏÑ†ÏÇ¨Ìï≠ Ï†ÅÏö©:")
    print("   - Adaptive Alpha: 0.5 ‚Üí 0.1 (ÌïôÏäµ ÏßÑÌñâÏóê Îî∞Îùº ÎèôÏ†Å Í∞êÏÜå)")
    print("   - Dynamic Temperature: 3.0 ‚Üí 2.0 ‚Üí 1.5 (Îã®Í≥ÑÏ†Å Í∞êÏÜå)")
    print("   - Extended KD: 40 ÏóêÌè¨ÌÅ¨ ÌõÑÏóêÎèÑ ÏßÄÏÜçÏ†Å KD (0.1 weight)")
    print("   - Î™©Ìëú: Î≤†Ïù¥Ïä§ÎùºÏù∏ ÎåÄÎπÑ 5%+ ÏÑ±Îä• Ìñ•ÏÉÅ")

    # Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ÏóêÏÑú 70 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä• Ï∂îÏ∂ú
    print("1Ô∏è‚É£ Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ÏóêÏÑú 70 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä• Ï∂îÏ∂ú")
    baseline_csv = "/workspace/projects/ed/jin/yolo-distiller/runs/detect/voc_baseline_yolo11s_optimized_20250928_095825/results.csv"
    baseline_metrics = extract_epoch_metrics(baseline_csv, 70)

    if baseline_metrics:
        print(f"   ‚úÖ Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä•:")
        print(f"      mAP50-95: {baseline_metrics['metrics/mAP50-95(B)']:.5f}")
        print(f"      mAP50: {baseline_metrics['metrics/mAP50(B)']:.5f}")
        print(f"      Precision: {baseline_metrics['metrics/precision(B)']:.5f}")
        print(f"      Recall: {baseline_metrics['metrics/recall(B)']:.5f}")
    else:
        print("   ‚ùå Î≤†Ïù¥Ïä§ÎùºÏù∏ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    # KD 150 ÏóêÌè¨ÌÅ¨ ÌïôÏäµ
    print("2Ô∏è‚É£ YOLOv11m ‚Üí YOLOv11s Extended KD 150 ÏóêÌè¨ÌÅ¨ ÌïôÏäµ")
    print("   ‚è∞ ÏòàÏÉÅ ÏÜåÏöîÏãúÍ∞Ñ: ~6ÏãúÍ∞Ñ")
    kd_result = run_kd_yolo11m_to_11s(epochs=150, batch=64, workers=12)
    kd_metrics = extract_metrics_from_results(kd_result["model_path"].parent.parent)

    # Í≤∞Í≥º ÎπÑÍµê
    print("‚úÖ Extended KD 150 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    print(f"üéì KD ÌïôÏäµ ÏãúÍ∞Ñ: {kd_result['training_time_str']}")
    print()
    print("üìä ÏÑ±Îä• ÎπÑÍµê (Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 vs KD 150):")
    print(f"   mAP50-95: {baseline_metrics['metrics/mAP50-95(B)']:.5f} ‚Üí {kd_metrics['metrics/mAP50-95(B)']:.5f} ({((kd_metrics['metrics/mAP50-95(B)'] - baseline_metrics['metrics/mAP50-95(B)']) / baseline_metrics['metrics/mAP50-95(B)'] * 100):+.3f}%)")
    print(f"   mAP50:    {baseline_metrics['metrics/mAP50(B)']:.5f} ‚Üí {kd_metrics['metrics/mAP50(B)']:.5f} ({((kd_metrics['metrics/mAP50(B)'] - baseline_metrics['metrics/mAP50(B)']) / baseline_metrics['metrics/mAP50(B)'] * 100):+.3f}%)")
    print(f"   Precision: {baseline_metrics['metrics/precision(B)']:.5f} ‚Üí {kd_metrics['metrics/precision(B)']:.5f} ({((kd_metrics['metrics/precision(B)'] - baseline_metrics['metrics/precision(B)']) / baseline_metrics['metrics/precision(B)'] * 100):+.3f}%)")
    print(f"   Recall:   {baseline_metrics['metrics/recall(B)']:.5f} ‚Üí {kd_metrics['metrics/recall(B)']:.5f} ({((kd_metrics['metrics/recall(B)'] - baseline_metrics['metrics/recall(B)']) / baseline_metrics['metrics/recall(B)'] * 100):+.3f}%)")

    # ÏóêÌè¨ÌÅ¨Î≥Ñ ÏßÑÏ†Ñ Î∂ÑÏÑù
    print()
    print("üìà KD ÌïôÏäµ ÏßÑÏ†Ñ Î∂ÑÏÑù:")
    print("   - 30 ÏóêÌè¨ÌÅ¨: Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 ÏóêÌè¨ÌÅ¨ÏôÄ Í±∞Ïùò ÎèôÎì± (Ïù¥ÎØ∏ Îã¨ÏÑ±)")
    print("   - 150 ÏóêÌè¨ÌÅ¨: Î≤†Ïù¥Ïä§ÎùºÏù∏ ÎåÄÎπÑ Ï∂îÍ∞Ä Í∞úÏÑ† Ìö®Í≥º ÌôïÏù∏")

def test_adaptive_kd_only():
    """Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ Ïû¨ÏÇ¨Ïö©ÌïòÏó¨ Adaptive KDÎßå ÌÖåÏä§Ìä∏ (30 ÏóêÌè¨ÌÅ¨)"""
    print("üöÄ Adaptive KD Only ÌÖåÏä§Ìä∏ ÏãúÏûë (30 ÏóêÌè¨ÌÅ¨)")
    print("üìä Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ Ïû¨ÏÇ¨Ïö©ÏúºÎ°ú ÏãúÍ∞Ñ Ï†àÏïΩ!")
    print("üìä ÏµúÏã† Í∞úÏÑ†ÏÇ¨Ìï≠ Ï†ÅÏö©:")
    print("   - Adaptive Alpha: 0.5 ‚Üí 0.1 (ÎèôÏ†Å Í∞êÏÜå)")
    print("   - Dynamic Temperature: 3.0 ‚Üí 2.0 (Îã®Í≥ÑÏ†Å Í∞êÏÜå)")
    print("   - KD Weight: 2.0 ‚Üí 0 (30 ÏóêÌè¨ÌÅ¨ÏóêÏÑú ÏûêÎèô Ï¢ÖÎ£å)")

    # Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ÏóêÏÑú 30 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä• Ï∂îÏ∂ú
    print("1Ô∏è‚É£ Í∏∞Ï°¥ Î≤†Ïù¥Ïä§ÎùºÏù∏ÏóêÏÑú 30 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä• Ï∂îÏ∂ú")
    baseline_csv = "/workspace/projects/ed/jin/yolo-distiller/runs/detect/voc_baseline_yolo11s_optimized_20250928_095825/results.csv"
    baseline_metrics = extract_epoch_metrics(baseline_csv, 30)

    if baseline_metrics:
        print(f"   ‚úÖ Î≤†Ïù¥Ïä§ÎùºÏù∏ 30 ÏóêÌè¨ÌÅ¨ ÏÑ±Îä•:")
        print(f"      mAP50-95: {baseline_metrics['metrics/mAP50-95(B)']:.5f}")
        print(f"      mAP50: {baseline_metrics['metrics/mAP50(B)']:.5f}")
        print(f"      Precision: {baseline_metrics['metrics/precision(B)']:.5f}")
        print(f"      Recall: {baseline_metrics['metrics/recall(B)']:.5f}")
    else:
        print("   ‚ùå Î≤†Ïù¥Ïä§ÎùºÏù∏ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    # KDÎßå ÏÉàÎ°ú ÌïôÏäµ (30 ÏóêÌè¨ÌÅ¨)
    print("2Ô∏è‚É£ YOLOv11m ‚Üí YOLOv11s Adaptive KD 30 ÏóêÌè¨ÌÅ¨ ÌïôÏäµ")
    kd_result = run_kd_yolo11m_to_11s(epochs=30, batch=64, workers=12)
    kd_metrics = extract_metrics_from_results(kd_result["model_path"].parent.parent)

    # Í≤∞Í≥º ÎπÑÍµê
    print("‚úÖ Adaptive KD Only ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    print(f"üéì KD ÌïôÏäµ ÏãúÍ∞Ñ: {kd_result['training_time_str']}")
    print()
    print("üìä ÏÑ±Îä• ÎπÑÍµê (30 ÏóêÌè¨ÌÅ¨):")
    print(f"   mAP50-95: {baseline_metrics['metrics/mAP50-95(B)']:.5f} ‚Üí {kd_metrics['metrics/mAP50-95(B)']:.5f} ({((kd_metrics['metrics/mAP50-95(B)'] - baseline_metrics['metrics/mAP50-95(B)']) / baseline_metrics['metrics/mAP50-95(B)'] * 100):+.3f}%)")
    print(f"   mAP50:    {baseline_metrics['metrics/mAP50(B)']:.5f} ‚Üí {kd_metrics['metrics/mAP50(B)']:.5f} ({((kd_metrics['metrics/mAP50(B)'] - baseline_metrics['metrics/mAP50(B)']) / baseline_metrics['metrics/mAP50(B)'] * 100):+.3f}%)")
    print(f"   Precision: {baseline_metrics['metrics/precision(B)']:.5f} ‚Üí {kd_metrics['metrics/precision(B)']:.5f} ({((kd_metrics['metrics/precision(B)'] - baseline_metrics['metrics/precision(B)']) / baseline_metrics['metrics/precision(B)'] * 100):+.3f}%)")
    print(f"   Recall:   {baseline_metrics['metrics/recall(B)']:.5f} ‚Üí {kd_metrics['metrics/recall(B)']:.5f} ({((kd_metrics['metrics/recall(B)'] - baseline_metrics['metrics/recall(B)']) / baseline_metrics['metrics/recall(B)'] * 100):+.3f}%)")

def test_adaptive_kd():
    """Adaptive KD ÌÖåÏä§Ìä∏ (30 ÏóêÌè¨ÌÅ¨ - Îπ†Î•∏ Í≤ÄÏ¶ù)"""
    print("üöÄ Adaptive KD ÌÖåÏä§Ìä∏ ÏãúÏûë (30 ÏóêÌè¨ÌÅ¨)")
    print("üìä ÏµúÏã† Í∞úÏÑ†ÏÇ¨Ìï≠ Ï†ÅÏö©:")
    print("   - Adaptive Alpha: 0.5 ‚Üí 0.1 (ÎèôÏ†Å Í∞êÏÜå)")
    print("   - Dynamic Temperature: 3.0 ‚Üí 2.0 (Îã®Í≥ÑÏ†Å Í∞êÏÜå)")
    print("   - KD Weight: 2.0 ‚Üí 0 (30 ÏóêÌè¨ÌÅ¨ÏóêÏÑú ÏûêÎèô Ï¢ÖÎ£å)")

    # Î≤†Ïù¥Ïä§ÎùºÏù∏ 30 ÏóêÌè¨ÌÅ¨
    print("1Ô∏è‚É£ YOLOv11s Î≤†Ïù¥Ïä§ÎùºÏù∏ 30 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    baseline_result = run_baseline_yolo11s(epochs=30, batch=64, workers=12)

    # KD 30 ÏóêÌè¨ÌÅ¨
    print("2Ô∏è‚É£ YOLOv11m ‚Üí YOLOv11s Adaptive KD 30 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    kd_result = run_kd_yolo11m_to_11s(epochs=30, batch=64, workers=12)

    print("‚úÖ Adaptive KD ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    print(f"üìä Î≤†Ïù¥Ïä§ÎùºÏù∏ ÏãúÍ∞Ñ: {baseline_result['training_time_str']}")
    print(f"üéì KD ÏãúÍ∞Ñ: {kd_result['training_time_str']}")

def test_thorough_kd():
    """Ï∂©Î∂ÑÌïú KD Ìö®Í≥º ÌÖåÏä§Ìä∏ (70 ÏóêÌè¨ÌÅ¨)"""
    print("üöÄ Ï∂©Î∂ÑÌïú KD Ìö®Í≥º ÌÖåÏä§Ìä∏ ÏãúÏûë (70 ÏóêÌè¨ÌÅ¨)")
    print("üìä ÏµúÏã† Í∞úÏÑ†ÏÇ¨Ìï≠ Ï†ÅÏö©:")
    print("   - Adaptive Alpha: 0.5 ‚Üí 0.1 (ÎèôÏ†Å Í∞êÏÜå)")
    print("   - Dynamic Temperature: 3.0 ‚Üí 2.0 ‚Üí 1.5 (Îã®Í≥ÑÏ†Å Í∞êÏÜå)")
    print("   - Early Stopping: 40 ÏóêÌè¨ÌÅ¨ ÌõÑ KD ÏµúÏÜåÌôî")

    # Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 ÏóêÌè¨ÌÅ¨
    print("1Ô∏è‚É£ YOLOv11s Î≤†Ïù¥Ïä§ÎùºÏù∏ 70 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    baseline_result = run_baseline_yolo11s(epochs=70, batch=64, workers=12)

    # KD 70 ÏóêÌè¨ÌÅ¨
    print("2Ô∏è‚É£ YOLOv11m ‚Üí YOLOv11s KD 70 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    kd_result = run_kd_yolo11m_to_11s(epochs=70, batch=64, workers=12)

    print("‚úÖ Ï∂©Î∂ÑÌïú KD ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    print(f"üìä Î≤†Ïù¥Ïä§ÎùºÏù∏ ÏãúÍ∞Ñ: {baseline_result['training_time_str']}")
    print(f"üéì KD ÏãúÍ∞Ñ: {kd_result['training_time_str']}")

def test_one_epoch():
    """1 ÏóêÌè¨ÌÅ¨ Í∞ÑÎã® ÌÖåÏä§Ìä∏"""
    print("üß™ 1 ÏóêÌè¨ÌÅ¨ Í∞ÑÎã® ÌÖåÏä§Ìä∏ ÏãúÏûë")

    # Î≤†Ïù¥Ïä§ÎùºÏù∏ 1 ÏóêÌè¨ÌÅ¨
    print("1Ô∏è‚É£ YOLOv11s Î≤†Ïù¥Ïä§ÎùºÏù∏ 1 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    baseline_result = run_baseline_yolo11s(epochs=1, batch=64, workers=12)

    # KD 1 ÏóêÌè¨ÌÅ¨
    print("2Ô∏è‚É£ YOLOv11m ‚Üí YOLOv11s KD 1 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏")
    kd_result = run_kd_yolo11m_to_11s(epochs=1, batch=64, workers=12)

    print("‚úÖ 1 ÏóêÌè¨ÌÅ¨ ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    print(f"üìä Î≤†Ïù¥Ïä§ÎùºÏù∏ ÏãúÍ∞Ñ: {baseline_result['training_time_str']}")
    print(f"üéì KD ÏãúÍ∞Ñ: {kd_result['training_time_str']}")

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            test_one_epoch()
        elif sys.argv[1] == "adaptive":
            test_adaptive_kd()
        elif sys.argv[1] == "kd_only":
            test_adaptive_kd_only()
        elif sys.argv[1] == "extended_150":
            test_extended_kd_150()
        elif sys.argv[1] == "thorough":
            test_thorough_kd()
        else:
            run_full_experiment()
    else:
        run_full_experiment()